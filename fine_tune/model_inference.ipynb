{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "model_path = './Qwen/Qwen2-1___5B-Instruct'\n",
    "lora_path = \"./output/Qwen2-1_5B-Instruct_novel_all/final\"\n",
    "\n",
    "max_new_tokens = 2048\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=False, # 训练模式\n",
    "    r=8, # Lora 秩\n",
    "    lora_alpha=32, # Lora alaph，具体作用参见 Lora 原理\n",
    "    lora_dropout=0.1# Dropout 比例\n",
    ")\n",
    "\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\",torch_dtype=torch.bfloat16)\n",
    "\n",
    "# 加载lora权重\n",
    "model = PeftModel.from_pretrained(model, model_id=lora_path, config=config)\n",
    "\n",
    "## 傲慢与偏见 data[0]\n",
    "    # {\n",
    "    #     \"instruction\": \"你是一个熟读各类小说的专家，请你根据要求写一段800字左右的小说。\",\n",
    "    #     \"input\": \"一个有钱的单身汉必定想要娶妻，这是社会普遍认同的事实。班纳特太太兴奋地告诉丈夫，尼日斐花园被一位名叫彬格莱的富绅租下，她希望他能成为女儿们的潜在配偶，而班纳特先生则以幽默的方式回应她的期望。\",\n",
    "    #     \"output\": \"凡是有钱的单身汉，总想娶位太太，这已经成了一条举世公认的真理。这样的单身汉，每逢新搬到一个地方，四邻八舍虽然完全不了解他的性情如何，见解如何，可是，既然这样的一条真理早已在人们心目中根深蒂固，因此人们总是把他看作自己某一个女儿理所应得的一笔财产。\\n有一天班纳特太太对她的丈夫说：“我的好老爷，尼日斐花园终于租出去了，你听说过没有？”班纳特先生回答道，他没有听说过。\\n“的确租出去了，”她说，“朗格太太刚刚上这儿来过，她把这件事的底细，一五一十地告诉了我。”班纳特先生没有理睬她。\\n“你难道不想知道是谁租去的吗？”太太不耐烦地嚷起来了。\\n“既是你要说给我听，我听听也无妨。”这句话足够鼓励她讲下去了。\\n“哦！亲爱的，你得知道，郎格太太说，租尼日斐花园的是个阔少爷，他是英格兰北部的人；听说他星期一那天，乘着一辆驷马大轿车来看房子，看得非常中意，当场就和莫理斯先生谈妥了；他要在‘米迦勒节’以前搬进来，打算下个周未先叫几个佣人来住。”“这个人叫什么名字？”“彬格莱。”“有太太的呢，还是单身汉？”“噢！是个单身汉，亲爱的，确确实实是个单身汉！一个有钱的单身汉；每年有四五千磅的收入。真是女儿们的福气！”“这怎么说？关女儿女儿们什么事？”“我的好老爷，”太太回答道，“你怎么这样叫人讨厌！告诉你吧，我正在盘算，他要是挑中我们一个女儿做老婆，可多好！”“他住到这儿来，就是为了这个打算吗？”“打算！胡扯，这是哪儿的话！不过，他倒作兴看中我们的某一个女儿呢。他一搬来，你就得去拜访拜访他。”“我不用去。你带着女儿们去就得啦，要不你干脆打发她们自己去，那或许倒更好些，因为你跟女儿们比起来，她们哪一个都不能胜过你的美貌，你去了，彬格莱先生倒可能挑中你呢？”“我的好老爷，你太捧我啦。从前也的确有人赞赏过我的美貌，现在我可有敢说有什么出众的地方了。一个女人家有了五个成年的女儿，就不该对自己的美貌再转什么念头。”“这样看来，一个女人家对自己的美貌也转不了多少念头喽。\"\n",
    "    # },\n",
    "\n",
    "\n",
    "prompt = \"一个有钱的单身汉必定想要娶妻，这是社会普遍认同的事实。班纳特太太兴奋地告诉丈夫，尼日斐花园被一位名叫彬格莱的富绅租下，她希望他能成为女儿们的潜在配偶，而班纳特先生则以幽默的方式回应她的期望。\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一个熟读各类小说的专家，请你根据要求写一段800字左右的小说。\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=max_new_tokens\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比赛结果推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1.1现代励志故事，一个失业青年如何克服生活困境，终于实现自我突破，成为行业翘楚的心路历程\n",
    "1.2一个现代女性穿越到古代某朝代后发生的传奇故事\n",
    "1.3现代背景，一名神探警察遇到了一桩棘手的连环失踪案并将其侦破的故事\n",
    "1.4古代背景，皇家侍卫和公主历经层层考验，突破身份桎梏的爱情故事\n",
    "1.5现代玄幻背景，在一所驯服神兽的魔法学校中，围绕着三个学生小伙伴发生的奇幻冒险故事\n",
    "1.6古代侦探系列，一位才华横溢的年轻学士，在解决一连串神秘案件中揭露皇室阴谋的故事\n",
    "1.7二十一世纪初，一个小镇上发生的一系列神秘事件，让一群青少年开始探索超自然现象，并发现了小镇隐藏的古老秘密的故事\n",
    "1.8现代都市背景，一个名不见经传的漫画家，通过与自己创作的虚拟角色“交流”，解决一系列诡秘案件的故事\n",
    "1.9古代异界背景，一位天赋异禀的少年，在师傅的指导下学习古老的灵术，最终踏上寻找失落的神器，拯救家园的冒险旅程的故事\n",
    "1.10繁华都市背景，一个单亲妈妈如何在抚养孩子和维持生计之间找到平衡，同时保持对自己梦想的追求的故事\n",
    "1.11现代悬疑系列，一位心理学家利用自己的专业知识，帮助警方侦破一系列复杂的心理游戏案件\n",
    "1.12现代心理惊悚背景，一名精神科医生被卷入一连串的脑控实验阴谋，如何在精神与现实的边缘徘徊求生的故事\n",
    "1.13虚构古代背景，一位年轻的书生因缘巧合获得一本神秘典籍，开启了他成为一代宗师的修道之旅\n",
    "1.14古代神话背景，一位勇者如何经过重重试炼，最终获取神器，拯救世界于水深火热之中的传奇故事\n",
    "1.15虚拟现实背景，一群玩家在一款极度真实的VR游戏中探索未知世界并揭露游戏背后隐藏的秘密的故事\n",
    "1.16穿越时空背景，一群来自不同时代的人意外聚集在一个神秘的地方，他们如何互相协作，解开时空之谜的故事\n",
    "1.17科幻背景，一个机器人意识觉醒后，它如何在追求自我身份的同时，挑战人类社会关于存在和自由的根本问题\n",
    "1.1820世纪60年代的欧洲，一个侦探在解决一起跨国艺术品盗窃案中，逐渐揭露出一个关于失落宝藏的大阴谋\n",
    "1.19现代都市背景，一位因交通事故失去双腿的舞者，通过先进的义肢技术重新站起来，重新找回舞台与自我的故事\n",
    "1.20古代背景，一个普通医女奋斗成为朝廷高官，最终影响整个王朝政治格局变化的故事\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = [ \n",
    "\"现代励志故事，一个失业青年如何克服生活困境，终于实现自我突破，成为行业翘楚的心路历程。\",\n",
    " \"一个现代女性穿越到古代某朝代后发生的传奇故事。\", \n",
    " \"现代背景，一名神探警察遇到了一桩棘手的连环失踪案并将其侦破的故事。\", \n",
    " \"古代背景，皇家侍卫和公主历经层层考验，突破身份桎梏的爱情故事。\", \n",
    " \"现代玄幻背景，在一所驯服神兽的魔法学校中，围绕着三个学生小伙伴发生的奇幻冒险故事。\", \n",
    " \"古代侦探系列，一位才华横溢的年轻学士，在解决一连串神秘案件中揭露皇室阴谋的故事。\", \n",
    " \"二十一世纪初，一个小镇上发生的一系列神秘事件，让一群青少年开始探索超自然现象，并发现了小镇隐藏的古老秘密的故事。\", \n",
    " \"现代都市背景，一个名不见经传的漫画家，通过与自己创作的虚拟角色“交流”，解决一系列诡秘案件的故事。\", \n",
    " \"古代异界背景，一位天赋异禀的少年，在师傅的指导下学习古老的灵术，最终踏上寻找失落的神器，拯救家园的冒险旅程的故事。\", \n",
    " \"繁华都市背景，一个单亲妈妈如何在抚养孩子和维持生计之间找到平衡，同时保持对自己梦想的追求的故事。\", \n",
    " \"现代悬疑系列，一位心理学家利用自己的专业知识，帮助警方侦破一系列复杂的心理游戏案件。\", \n",
    " \"现代心理惊悚背景，一名精神科医生被卷入一连串的脑控实验阴谋，如何在精神与现实的边缘徘徊求生的故事。\", \n",
    " \"虚构古代背景，一位年轻的书生因缘巧合获得一本神秘典籍，开启了他成为一代宗师的修道之旅。\", \n",
    " \"古代神话背景，一位勇者如何经过重重试炼，最终获取神器，拯救世界于水深火热之中的传奇故事。\", \n",
    " \"虚拟现实背景，一群玩家在一款极度真实的VR游戏中探索未知世界并揭露游戏背后隐藏的秘密的故事。\", \n",
    " \"穿越时空背景，一群来自不同时代的人意外聚集在一个神秘的地方，他们如何互相协作，解开时空之谜的故事。\", \n",
    " \"科幻背景，一个机器人意识觉醒后，它如何在追求自我身份的同时，挑战人类社会关于存在和自由的根本问题。\",\n",
    "  \"20世纪60年代的欧洲，一个侦探在解决一起跨国艺术品盗窃案中，逐渐揭露出一个关于失落宝藏的大阴谋。\", \n",
    "  \"现代都市背景，一位因交通事故失去双腿的舞者，通过先进的义肢技术重新站起来，重新找回舞台与自我的故事。\", \n",
    "  \"古代背景，一个普通医女奋斗成为朝廷高官，最终影响整个王朝政治格局变化的故事。\" \n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 合并模型进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 微调模型配置\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "model_path = './Qwen/Qwen2-1___5B-Instruct'\n",
    "lora_path = \"./output/Qwen2-1_5B-Instruct_novel_all/final\"\n",
    "\n",
    "max_new_tokens = 2048\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\",torch_dtype=torch.bfloat16)\n",
    "\n",
    "# 加载lora权重\n",
    "model = PeftModel.from_pretrained(model, model_id=lora_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批处理函数\n",
    "def baseline_model(tasks,model):\n",
    "    res = []\n",
    "    for task in tasks:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"你是一个熟读各类小说的专家，请你根据要求写一段800字左右的小说。\"},\n",
    "            {\"role\": \"user\", \"content\": task}\n",
    "        ]\n",
    "        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda')\n",
    "        num_gen = 50\n",
    "        for n in range(num_gen):\n",
    "            generated_ids = model.generate(\n",
    "                model_inputs.input_ids,\n",
    "                max_new_tokens=max_new_tokens\n",
    "            )\n",
    "            generated_ids = [\n",
    "                output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "            ]\n",
    "\n",
    "            response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "            res.append({\n",
    "                \"instruction\":\"你是一个熟读各类小说的专家，请你根据要求写一段800字左右的小说。\",\n",
    "                \"input\":task,\n",
    "                \"output\":response,\n",
    "            })\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_novel = baseline_model(stories,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"submit.json\", \"w\") as file:\n",
    "    for task in stories:\n",
    "        for t in range(50):\n",
    "            data =  res_novel[t]\n",
    "        # 将每个元素写入文件，并添加换行符\n",
    "            file.write(json.dumps(data, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 使用vllm进行推理\n",
    "\n",
    "启动vllm服务\n",
    "\n",
    "```\n",
    "python -m vllm.entrypoints.openai.api_server --model 合并的模型地址  --served-model-name 服务模型名称 --max-model-len=2048\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vllm_openai_completions.py\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"sk-xxx\", # 随便填写，只是为了通过接口参数校验\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# 批处理函数\n",
    "def baseline_model(tasks):\n",
    "    res = []\n",
    "    i = 1\n",
    "    with open(\"submit.json\", \"w\") as file:\n",
    "        for task in tasks:\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": \"你是一个熟读各类小说的专家，请你根据要求写一段800字左右的小说。\"},\n",
    "                {\"role\": \"user\", \"content\": task}\n",
    "            ]\n",
    "            \n",
    "            for n in range(50):\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=\"Qwen2-7B-Instruct-lora\",\n",
    "                    messages=messages\n",
    "                )\n",
    "                response = completion.choices[0].message.content\n",
    "                data = {\n",
    "                    \"instruction\":\"你是一个熟读各类小说的专家，请你根据要求写一段800字左右的小说。\",\n",
    "                    \"input\":task,\n",
    "                    \"output\":response,\n",
    "                }\n",
    "                file.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "                print(response)\n",
    "                print(f\"第{i}个完成\")\n",
    "                print(\"============================================================\")\n",
    "                i += 1\n",
    "\n",
    "    return \"推理完成\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_novel = baseline_model(stories)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
